\section{Introduction} \label{section:introduction}

This report presents the algorithms, performance results and respective analysis of the first project in the Parallel and Distributed Computing course. The objective of this project was to evaluate and compare the performance of different memory access patterns and parallelization techniques.

Matrix multiplication was chosen as the central problem due to its relative simplicity and its suitability for testing various performance-related aspects. In particular, we examine how operating systems and hardware handle memory access. Specifically, most CPUs employ techniques such as caching, where data is temporarily stored closer to the CPU for faster access, and prefetching, where data is retrieved in contiguous blocks (cache lines). Consequently, when one element is accessed, the processor often fetches adjacent elements as well and keeps them cached. To observe this effect, we implemented three single-core algorithms. To explore how different parallelization strategies can improve performance, we also implemented two multi-core algorithms (see \hyperref[section:algorithms]{Algorithms Explanation} section).

By developing the code for these tasks, we became more familiar with modern and high performance C++ and Lua, since we chose it as our alternative implementation language. Moreover, we also had to research about matrix multiplication algorithms and, in order to implement multi-core solutions, we explored and experimented with the OpenMP standard, allowing us to learn more about CPU multithreading.
